{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Preprocess import label_for_nn\n",
    "from cnn_model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_path = '/home/user01/Desktop/DDSM/4_benign_Pleo_10_ROI_subpic'#input('良性子图路径')#\n",
    "cancer_path = '/home/user01/Desktop/DDSM/4_cancer_Pleo_10_ROI_subpic'#input('恶性子图路径')#\n",
    "saver_path = '/home/user01/Desktop/DDSM/model/AlexNet_v1'#input('模型保存路径')#\n",
    "size = 128\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainsets_and_testsets(benign_path,cancer_path):\n",
    "    (train_x ,train_y),(test_x,test_y) = label_for_nn(benign_path,cancer_path,scale=0.2,kind='RGB')\n",
    "    train_x = train_x.reshape(train_x.shape[0],size,size,3).astype('float32')/255.0\n",
    "    test_x = test_x.reshape(test_x.shape[0],size,size,3).astype('float32')/255.0\n",
    "    return  test_x ,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_P(x,W,s):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,s,s,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W,s):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,s,s,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_test():\n",
    "    x = tf.placeholder(tf.float32, [None, 128, 128, 3])\n",
    "    y = tf.placeholder(tf.float32, [None, 2])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    y_pre = model(x,keep_prob)\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pre), reduction_indices=[1]))\n",
    "    y_pre_label = tf.argmax(y_pre,1)\n",
    "    y_label = tf.argmax(y,1)\n",
    "    a = tf.add(y_pre_label, 1)\n",
    "    b = tf.add(y_label, 3)\n",
    "    c = tf.multiply(a, b)\n",
    "    tp = tf.reduce_sum(tf.cast(tf.equal(c, 8), tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast(tf.equal(c, 6), tf.float32))\n",
    "    tn = tf.reduce_sum(tf.cast(tf.equal(c, 3), tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(tf.equal(c, 4), tf.float32))\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    tf.summary.scalar('test_Sensitivity', tpr)\n",
    "    tf.summary.scalar('test_Specificity', tnr)\n",
    "    correct_l1 = tf.equal(y_pre_label, y_label)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_l1, tf.float32))\n",
    "    tf.summary.scalar('test_loss', cross_entropy)\n",
    "    tf.summary.scalar('test_accuracy', accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        test_accuracy = 0\n",
    "        writer = tf.summary.FileWriter(saver_path, sess.graph)\n",
    "        saver.restore(sess,saver_path+'/AlexNet')\n",
    "        test_accuracy = 0\n",
    "        test_sensitivity = 0\n",
    "        test_specificity = 0\n",
    "        test_loss = 0\n",
    "        for n in range(0,100):\n",
    "            test_x, test_y = get_trainsets_and_testsets(benign_path,cancer_path)\n",
    "            acc,sen,spec,loss,summary = sess.run([accuracy,tpr,tnr,cross_entropy,merged_summary_op],feed_dict={x:test_x,y:test_y,keep_prob:1.0})\n",
    "            test_accuracy += acc\n",
    "            test_sensitivity += sen\n",
    "            test_specificity +=spec\n",
    "            test_loss += loss\n",
    "            print(\"{0:3d} accuracy:{1:>10.9f} loss:{2:>10.9f} specificity:{3:>10.9f} sensitivity:{4:>10.9f}\".format(n,acc,loss,sen,spec))\n",
    "            writer.add_summary(summary=summary, global_step=n)\n",
    "        print(\"accuracy:{0:<6.3f}% loss:{1:<6.3f}% specificity:{2:<6.3f}% sensitivity:{3:<6.3f}%\".format(test_accuracy,test_loss,test_sensitivity,test_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "INFO:tensorflow:Restoring parameters from /home/user01/Desktop/DDSM/model/AlexNet_v1/AlexNet\n",
      "  0 accuracy:0.959999979 loss:0.204924643 specificity:0.923076928 sensitivity:1.000000000\n",
      "  1 accuracy:1.000000000 loss:0.008384398 specificity:1.000000000 sensitivity:1.000000000\n",
      "  2 accuracy:1.000000000 loss:0.001599544 specificity:1.000000000 sensitivity:1.000000000\n",
      "  3 accuracy:1.000000000 loss:0.010582102 specificity:1.000000000 sensitivity:1.000000000\n",
      "  4 accuracy:0.983333349 loss:0.048856378 specificity:0.961538434 sensitivity:1.000000000\n",
      "  5 accuracy:1.000000000 loss:0.000150355 specificity:1.000000000 sensitivity:1.000000000\n",
      "  6 accuracy:1.000000000 loss:0.005218505 specificity:1.000000000 sensitivity:1.000000000\n",
      "  7 accuracy:1.000000000 loss:0.006811084 specificity:1.000000000 sensitivity:1.000000000\n",
      "  8 accuracy:0.981818199 loss:0.038483623 specificity:0.967741907 sensitivity:1.000000000\n",
      "  9 accuracy:0.980000019 loss:0.040587954 specificity:0.954545438 sensitivity:1.000000000\n",
      " 10 accuracy:0.979591846 loss:0.030119959 specificity:0.956521749 sensitivity:1.000000000\n",
      " 11 accuracy:1.000000000 loss:0.001414828 specificity:1.000000000 sensitivity:1.000000000\n",
      " 12 accuracy:0.979166687 loss:0.035593905 specificity:0.958333313 sensitivity:1.000000000\n",
      " 13 accuracy:0.980769217 loss:0.031183627 specificity:0.959999979 sensitivity:1.000000000\n",
      " 14 accuracy:0.983333349 loss:0.150394484 specificity:0.956521749 sensitivity:1.000000000\n",
      " 15 accuracy:0.981818199 loss:0.040250197 specificity:0.959999979 sensitivity:1.000000000\n",
      " 16 accuracy:0.979591846 loss:0.039954633 specificity:0.956521749 sensitivity:1.000000000\n",
      " 17 accuracy:0.957446814 loss:0.234435096 specificity:0.933333337 sensitivity:1.000000000\n",
      " 18 accuracy:1.000000000 loss:0.009709992 specificity:1.000000000 sensitivity:1.000000000\n",
      " 19 accuracy:1.000000000 loss:0.000240954 specificity:1.000000000 sensitivity:1.000000000\n",
      " 20 accuracy:1.000000000 loss:0.000886329 specificity:1.000000000 sensitivity:1.000000000\n",
      " 21 accuracy:0.980392158 loss:0.167379797 specificity:0.962962985 sensitivity:1.000000000\n",
      " 22 accuracy:1.000000000 loss:0.005450808 specificity:1.000000000 sensitivity:1.000000000\n",
      " 23 accuracy:1.000000000 loss:0.000176806 specificity:1.000000000 sensitivity:1.000000000\n",
      " 24 accuracy:0.933333337 loss:0.102043599 specificity:0.869565189 sensitivity:1.000000000\n",
      " 25 accuracy:0.958333313 loss:0.207786262 specificity:0.923076928 sensitivity:1.000000000\n",
      " 26 accuracy:1.000000000 loss:0.006989649 specificity:1.000000000 sensitivity:1.000000000\n",
      " 27 accuracy:0.980000019 loss:0.047713362 specificity:0.962962985 sensitivity:1.000000000\n",
      " 28 accuracy:0.983050823 loss:0.165931955 specificity:0.961538434 sensitivity:1.000000000\n",
      " 29 accuracy:0.984126985 loss:0.138626859 specificity:0.967741907 sensitivity:1.000000000\n",
      " 30 accuracy:0.980769217 loss:0.171362296 specificity:0.961538434 sensitivity:1.000000000\n",
      " 31 accuracy:0.971428573 loss:0.053292386 specificity:0.933333337 sensitivity:1.000000000\n",
      " 32 accuracy:0.980000019 loss:0.045086123 specificity:0.964285731 sensitivity:1.000000000\n",
      " 33 accuracy:1.000000000 loss:0.004696982 specificity:1.000000000 sensitivity:1.000000000\n",
      " 34 accuracy:1.000000000 loss:0.005687099 specificity:1.000000000 sensitivity:1.000000000\n",
      " 35 accuracy:0.982758641 loss:0.030355718 specificity:0.969696999 sensitivity:1.000000000\n",
      " 36 accuracy:1.000000000 loss:0.010734908 specificity:1.000000000 sensitivity:1.000000000\n",
      " 37 accuracy:1.000000000 loss:0.005489331 specificity:1.000000000 sensitivity:1.000000000\n",
      " 38 accuracy:0.980000019 loss:0.035984527 specificity:0.952380955 sensitivity:1.000000000\n",
      " 39 accuracy:1.000000000 loss:0.014473949 specificity:1.000000000 sensitivity:1.000000000\n",
      " 40 accuracy:1.000000000 loss:0.000804589 specificity:1.000000000 sensitivity:1.000000000\n",
      " 41 accuracy:0.982142866 loss:0.035561141 specificity:0.965517223 sensitivity:1.000000000\n",
      " 42 accuracy:0.980000019 loss:0.180335164 specificity:0.964285731 sensitivity:1.000000000\n",
      " 43 accuracy:0.981132090 loss:0.183208898 specificity:0.966666639 sensitivity:1.000000000\n",
      " 44 accuracy:0.983050823 loss:0.028918101 specificity:0.962962985 sensitivity:1.000000000\n",
      " 45 accuracy:0.977777779 loss:0.037669677 specificity:0.964285731 sensitivity:1.000000000\n",
      " 46 accuracy:0.980000019 loss:0.040000595 specificity:0.961538434 sensitivity:1.000000000\n",
      " 47 accuracy:0.979166687 loss:0.177440822 specificity:0.959999979 sensitivity:1.000000000\n",
      " 48 accuracy:0.975609779 loss:0.214258745 specificity:0.962962985 sensitivity:1.000000000\n",
      " 49 accuracy:0.982758641 loss:0.155216411 specificity:0.970588207 sensitivity:1.000000000\n",
      " 50 accuracy:0.978723407 loss:0.182045206 specificity:0.954545438 sensitivity:1.000000000\n",
      " 51 accuracy:0.980392158 loss:0.047056723 specificity:0.959999979 sensitivity:1.000000000\n",
      " 52 accuracy:1.000000000 loss:0.004623625 specificity:1.000000000 sensitivity:1.000000000\n",
      " 53 accuracy:1.000000000 loss:0.002149940 specificity:1.000000000 sensitivity:1.000000000\n",
      " 54 accuracy:1.000000000 loss:0.005919419 specificity:1.000000000 sensitivity:1.000000000\n",
      " 55 accuracy:0.983606577 loss:0.027815698 specificity:0.958333313 sensitivity:1.000000000\n",
      " 56 accuracy:1.000000000 loss:0.010377310 specificity:1.000000000 sensitivity:1.000000000\n",
      " 57 accuracy:0.961538434 loss:0.204101384 specificity:0.933333337 sensitivity:1.000000000\n",
      " 58 accuracy:0.980769217 loss:0.038551901 specificity:0.956521749 sensitivity:1.000000000\n",
      " 59 accuracy:1.000000000 loss:0.014794723 specificity:1.000000000 sensitivity:1.000000000\n",
      " 60 accuracy:0.985507250 loss:0.032040060 specificity:0.969696999 sensitivity:1.000000000\n",
      " 61 accuracy:1.000000000 loss:0.010493705 specificity:1.000000000 sensitivity:1.000000000\n",
      " 62 accuracy:0.982142866 loss:0.032923218 specificity:0.964285731 sensitivity:1.000000000\n",
      " 63 accuracy:1.000000000 loss:0.006014824 specificity:1.000000000 sensitivity:1.000000000\n",
      " 64 accuracy:0.977272749 loss:0.035850301 specificity:0.947368443 sensitivity:1.000000000\n",
      " 65 accuracy:1.000000000 loss:0.000618378 specificity:1.000000000 sensitivity:1.000000000\n",
      " 66 accuracy:0.980000019 loss:0.041357506 specificity:0.952380955 sensitivity:1.000000000\n",
      " 67 accuracy:1.000000000 loss:0.008244756 specificity:1.000000000 sensitivity:1.000000000\n",
      " 68 accuracy:0.980769217 loss:0.048078571 specificity:0.956521749 sensitivity:1.000000000\n",
      " 69 accuracy:0.967213094 loss:0.172566742 specificity:0.925925910 sensitivity:1.000000000\n",
      " 70 accuracy:0.979591846 loss:0.038549546 specificity:0.958333313 sensitivity:1.000000000\n",
      " 71 accuracy:1.000000000 loss:0.000063807 specificity:1.000000000 sensitivity:1.000000000\n",
      " 72 accuracy:1.000000000 loss:0.004683687 specificity:1.000000000 sensitivity:1.000000000\n",
      " 73 accuracy:1.000000000 loss:0.001401948 specificity:1.000000000 sensitivity:1.000000000\n",
      " 74 accuracy:0.981818199 loss:0.038084473 specificity:0.954545438 sensitivity:1.000000000\n",
      " 75 accuracy:1.000000000 loss:0.015853724 specificity:1.000000000 sensitivity:1.000000000\n",
      " 76 accuracy:0.979591846 loss:0.045698930 specificity:0.952380955 sensitivity:1.000000000\n",
      " 77 accuracy:1.000000000 loss:0.010120184 specificity:1.000000000 sensitivity:1.000000000\n",
      " 78 accuracy:0.959183693 loss:0.216178745 specificity:0.928571403 sensitivity:1.000000000\n",
      " 79 accuracy:0.978723407 loss:0.186498269 specificity:0.959999979 sensitivity:1.000000000\n",
      " 80 accuracy:0.980000019 loss:0.038385313 specificity:0.961538434 sensitivity:1.000000000\n",
      " 81 accuracy:1.000000000 loss:0.000702184 specificity:1.000000000 sensitivity:1.000000000\n",
      " 82 accuracy:1.000000000 loss:0.000088378 specificity:1.000000000 sensitivity:1.000000000\n",
      " 83 accuracy:0.980000019 loss:0.034017257 specificity:0.959999979 sensitivity:1.000000000\n",
      " 84 accuracy:0.968253970 loss:0.173553646 specificity:0.928571403 sensitivity:1.000000000\n",
      " 85 accuracy:0.980000019 loss:0.029559042 specificity:0.954545438 sensitivity:1.000000000\n",
      " 86 accuracy:0.953488350 loss:0.243543252 specificity:0.923076928 sensitivity:1.000000000\n",
      " 87 accuracy:0.959999979 loss:0.212434575 specificity:0.928571403 sensitivity:1.000000000\n",
      " 88 accuracy:0.981132090 loss:0.029443212 specificity:0.958333313 sensitivity:1.000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89 accuracy:0.975609779 loss:0.041372962 specificity:0.944444418 sensitivity:1.000000000\n",
      " 90 accuracy:0.962264180 loss:0.058346689 specificity:0.925925910 sensitivity:1.000000000\n",
      " 91 accuracy:0.978260875 loss:0.047607303 specificity:0.954545438 sensitivity:1.000000000\n",
      " 92 accuracy:0.980769217 loss:0.043971650 specificity:0.968750000 sensitivity:1.000000000\n",
      " 93 accuracy:0.956521749 loss:0.220558643 specificity:0.920000017 sensitivity:1.000000000\n",
      " 94 accuracy:0.977272749 loss:0.041627195 specificity:0.961538434 sensitivity:1.000000000\n",
      " 95 accuracy:1.000000000 loss:0.000997724 specificity:1.000000000 sensitivity:1.000000000\n",
      " 96 accuracy:0.974358976 loss:0.041619677 specificity:0.949999988 sensitivity:1.000000000\n",
      " 97 accuracy:0.983870983 loss:0.028454915 specificity:0.966666639 sensitivity:1.000000000\n",
      " 98 accuracy:0.981481493 loss:0.033702180 specificity:0.970588207 sensitivity:1.000000000\n",
      " 99 accuracy:1.000000000 loss:0.004874317 specificity:1.000000000 sensitivity:1.000000000\n",
      "accuracy:98.493% loss:6.020 % specificity:97.006% sensitivity:100.000%\n"
     ]
    }
   ],
   "source": [
    "cnn_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
