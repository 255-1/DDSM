{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot as plt\n",
    "from Preprocess import label_for_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_path = '/home/user01/Desktop/DDSM/4_benign_Pleo_10_ROI_subpic'#input('良性子图路径')#\n",
    "cancer_path = '/home/user01/Desktop/DDSM/4_cancer_Pleo_10_ROI_subpic'#input('恶性子图路径')#\n",
    "saver_path = '/home/user01/Desktop/DDSM/model/VGG11'#input('模型保存路径')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "train_time = 100\n",
    "batch_size = 10\n",
    "learning_rate = 1e-5\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainsets_and_testsets():\n",
    "    (train_x ,train_y),(test_x,test_y) = label_for_nn(benign_path,cancer_path,scale=0.2,kind='RGB')\n",
    "    train_x = train_x.reshape(train_x.shape[0],size,size,3).astype('float32')/255.0\n",
    "    test_x = test_x.reshape(test_x.shape[0],size,size,3).astype('float32')/255.0\n",
    "    return train_x , test_x ,train_y ,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.027)\n",
    "    return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biases_variable(shape,name):\n",
    "    initial = tf.constant(0.0,shape=shape)\n",
    "    return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_P(x,W,s):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,s,s,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W,s):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,s,s,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_train():\n",
    "    with tf.name_scope('inputs'):\n",
    "        x = tf.placeholder(tf.float32, [None, size, size, 3])\n",
    "        y = tf.placeholder(tf.float32, [None, 2])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "    #conv1#\n",
    "    with tf.name_scope('layer_1'):\n",
    "        with tf.name_scope('weight_1'):\n",
    "            w_conv1 = Weight_variable([3,3,3,64],'w_1')\n",
    "        with tf.name_scope('biases_1'):\n",
    "            b_conv1 = biases_variable([64],'b_1')\n",
    "        with tf.name_scope('conv_1'):\n",
    "            conv1 = tf.nn.relu(conv2d_P(x,w_conv1,1)+b_conv1)\n",
    "        with tf.name_scope('pool_1'):\n",
    "            pool1 = max_pooling2x2(conv1)\n",
    "    #conv2#\n",
    "    with tf.name_scope('layer_2'):\n",
    "        with tf.name_scope('weight_2'):\n",
    "            w_conv2 = Weight_variable([3,3,64,128],'w_2')\n",
    "        with tf.name_scope('biases_2'):\n",
    "            b_conv2 = biases_variable([128],'b_2')\n",
    "        with tf.name_scope('conv_2'):\n",
    "            conv2 = tf.nn.relu(conv2d_P(pool1,w_conv2,1)+b_conv2)\n",
    "        with tf.name_scope('pool_2'):\n",
    "            pool2 = max_pooling2x2(conv2)\n",
    "\n",
    "    #conv3#\n",
    "    with tf.name_scope('layer_3'):\n",
    "        with tf.name_scope('weight_3'):\n",
    "            w_conv3 = Weight_variable([3,3,128,256],'w_3')\n",
    "        with tf.name_scope('biases_3'):\n",
    "            b_conv3 = biases_variable([256],'b_3')\n",
    "        with tf.name_scope('conv_3'):\n",
    "            conv3 = tf.nn.relu(conv2d_P(pool2,w_conv3,1)+b_conv3)\n",
    "\n",
    "    #conv4#\n",
    "    with tf.name_scope('layer_4'):\n",
    "        with tf.name_scope('weight_4'):\n",
    "            w_conv4 = Weight_variable([3,3,256,256],'w_4')\n",
    "        with tf.name_scope('biases_4'):\n",
    "            b_conv4 = biases_variable([256],'b_4')\n",
    "        with tf.name_scope('conv_4'):\n",
    "            conv4 = tf.nn.relu(conv2d_P(conv3,w_conv4,1)+b_conv4)\n",
    "        with tf.name_scope('pool_3'):\n",
    "            pool3 = max_pooling2x2(conv4)\n",
    "\n",
    "    #conv5#\n",
    "    with tf.name_scope('layer_5'):\n",
    "        with tf.name_scope('weight_5'):\n",
    "            w_conv5 = Weight_variable([3,3,256,512],'w_5')\n",
    "        with tf.name_scope('biases_5'):\n",
    "            b_conv5 = biases_variable([512],'b_5')\n",
    "        with tf.name_scope('conv_5'):\n",
    "            conv5 = tf.nn.relu(conv2d_P(pool3,w_conv5,1)+b_conv5)\n",
    "\n",
    "    #conv6#\n",
    "    with tf.name_scope('layer_6'):\n",
    "        with tf.name_scope('weight_6'):\n",
    "            w_conv6 = Weight_variable([3,3,512,512],'w_6')\n",
    "        with tf.name_scope('biases_6'):\n",
    "            b_conv6 = biases_variable([512],'b_6')\n",
    "        with tf.name_scope('conv_6'):\n",
    "            conv6 = tf.nn.relu(conv2d_P(conv5,w_conv6,1)+b_conv6)\n",
    "        with tf.name_scope('pool_4'):\n",
    "            pool4 = max_pooling2x2(conv6)\n",
    "\n",
    "    #conv7#\n",
    "    with tf.name_scope('layer_7'):\n",
    "        with tf.name_scope('weight_7'):\n",
    "            w_conv7 = Weight_variable([3,3,512,512],'w_7')\n",
    "        with tf.name_scope('biases_7'):\n",
    "            b_conv7 = biases_variable([512],'b_7')\n",
    "        with tf.name_scope('conv_7'):\n",
    "            conv7 = tf.nn.relu(conv2d_P(pool4,w_conv7,1)+b_conv7)\n",
    "\n",
    "    #conv8#\n",
    "    with tf.name_scope('layer_8'):\n",
    "        with tf.name_scope('weight_8'):\n",
    "            w_conv8 = Weight_variable([3,3,512,512],'w_8')\n",
    "        with tf.name_scope('biases_8'):\n",
    "            b_conv8 = biases_variable([512],'b_8')\n",
    "        with tf.name_scope('conv_8'):\n",
    "            conv8 = tf.nn.relu(conv2d_P(conv7,w_conv8,1)+b_conv8)\n",
    "        with tf.name_scope('pool_5'):\n",
    "            pool5 = max_pooling2x2(conv8)\n",
    "    print(pool5.shape)\n",
    "    #func1#\n",
    "    with tf.name_scope('layer_9'):\n",
    "        with tf.name_scope('weight_9'):\n",
    "            w_conv9 = Weight_variable([3*3*512,4096],'w_9')\n",
    "        with tf.name_scope('biases_9'):\n",
    "            b_conv9 = biases_variable([4096],'b_9')\n",
    "        with tf.name_scope('fc_1'):\n",
    "            pool5_flat = tf.reshape(pool5,[-1,3*3*512])\n",
    "            fc1 = tf.nn.relu(tf.matmul(pool5_flat,w_conv9) + b_conv9)\n",
    "            fc1_drop = tf.nn.dropout(fc1,keep_prob)\n",
    "    #func2#\n",
    "    with tf.name_scope('layer_10'):\n",
    "        with tf.name_scope('weight_10'):\n",
    "            w_conv10 = Weight_variable([4096,4096],'w_10')\n",
    "        with tf.name_scope('biases_15'):\n",
    "            b_conv10 = biases_variable([4096],'b_10')\n",
    "        with tf.name_scope('fc_2'):\n",
    "            fc2 = tf.nn.relu(tf.matmul(fc1_drop,w_conv10) + b_conv10)\n",
    "            fc2_drop = tf.nn.dropout(fc2, keep_prob)\n",
    "    #func3#\n",
    "    with tf.name_scope('layer_11'):\n",
    "        with tf.name_scope('weight_11'):\n",
    "            w_conv11 = Weight_variable([4096,2],'w_11')\n",
    "        with tf.name_scope('biases_16'):\n",
    "            b_conv11 = biases_variable([2],'b_11')\n",
    "        with tf.name_scope('fc_3'):\n",
    "            y_pre = tf.nn.softmax(tf.matmul(fc2_drop,w_conv11) + b_conv11)\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pre), reduction_indices=[1]))\n",
    "    with tf.name_scope('trian'):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "    y_pre_label = tf.argmax(y_pre,1)\n",
    "    y_label = tf.argmax(y,1)\n",
    "    a = tf.add(y_pre_label,1)\n",
    "    b = tf.add(y_label,3)\n",
    "    c = tf.multiply(a,b)\n",
    "    tp = tf.reduce_sum(tf.cast(tf.equal(c,8),tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast(tf.equal(c,6),tf.float32))\n",
    "    tn = tf.reduce_sum(tf.cast(tf.equal(c,3),tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(tf.equal(c,4),tf.float32))\n",
    "    tpr = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    tf.summary.scalar('Sensitivity', tpr)\n",
    "    tf.summary.scalar('Specificity', tnr)\n",
    "    correct_l1 = tf.equal(y_pre_label,y_label)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_l1,tf.float32))\n",
    "    tf.summary.scalar('loss',cross_entropy)\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    init = tf.global_variables_initializer()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    saver = tf.train.Saver({'w_1': w_conv1, 'b_1': b_conv1,\n",
    "                            'w_2': w_conv2, 'b_2': b_conv2,\n",
    "                            'w_3': w_conv3, 'b_3': b_conv3,\n",
    "                            'w_4': w_conv4, 'b_4': b_conv4,\n",
    "                            'w_5': w_conv5, 'b_5': b_conv5,\n",
    "                            'w_6': w_conv6, 'b_6': b_conv6,\n",
    "                            'w_7': w_conv7, 'b_7': b_conv7,\n",
    "                            'w_8': w_conv8, 'b_8': b_conv8,\n",
    "                            'w_9': w_conv9, 'b_9': b_conv9,\n",
    "                            'w_10': w_conv10, 'b_10': b_conv10,\n",
    "                            'w_11': w_conv11, 'b_11': b_conv11\n",
    "                            })\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)\n",
    "        writer = tf.summary.FileWriter(saver_path, sess.graph)\n",
    "        sum_test_acc = 0\n",
    "        train_x,test_x,train_y,test_y=get_trainsets_and_testsets()#获取训练集和测试集\n",
    "        num_batch = len(train_x)//batch_size\n",
    "        for n in range(1,train_time+1):\n",
    "            sum_train_acc = 0\n",
    "            av_train_loss = 0\n",
    "            for i in range(num_batch):#训练\n",
    "                batch_x = train_x[i*batch_size : (i+1)*batch_size]\n",
    "                batch_y = train_y[i*batch_size : (i+1)*batch_size]\n",
    "                _,loss,train_acc= sess.run([train_step,cross_entropy,accuracy],feed_dict={x:batch_x,y:batch_y,keep_prob:dropout_rate})\n",
    "                sum_train_acc += train_acc\n",
    "                av_train_loss += loss\n",
    "            av_train_loss /= num_batch\n",
    "            sum_train_acc /= num_batch\n",
    "            test_acc, pre, test_loss = sess.run([accuracy, y_pre, cross_entropy],feed_dict={x: test_x, y: test_y, keep_prob: 1.0})\n",
    "            if n>30:\n",
    "                sum_test_acc += test_acc\n",
    "            if n%10==0:#验证\n",
    "                print('{0:3d} train_loss: {1:>10.9f} test_loss: {2:>10.9f} train_accuracy:{3:>10.9f} test_accuracy:{4:>10.9f}'.format(n,av_train_loss,test_loss,sum_train_acc,test_acc))\n",
    "            summary = sess.run(merged_summary_op,feed_dict={x:test_x,y:test_y,keep_prob:1.0})\n",
    "            writer.add_summary(summary=summary, global_step=n)\n",
    "        #ROC曲线\n",
    "        y_,y_p= sess.run([y_label,y_pre],feed_dict={x: test_x, y: test_y, keep_prob: 1.0})\n",
    "        temp = []\n",
    "        for i in range(len(y_p)):\n",
    "            temp.append(y_p[i][1])\n",
    "        fpr,tpr,thresholds = roc_curve(y_,temp)\n",
    "        n_auc = auc(fpr,tpr)\n",
    "        plt.plot(fpr,tpr,linewidth=2)\n",
    "        plt.plot([0,1],[0,1],'k--')\n",
    "        plt.axis([0,1,0,1])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        text = 'AUC:'+str(n_auc)[0:5]\n",
    "        plt.text(0.7,0.2,text,fontdict={'size':'12','color':'b'})\n",
    "        saver.save(sess,saver_path+'/VGG11')\n",
    "        print(sum_test_acc/(train_time-30))\n",
    "        plt.savefig(saver_path+'/VGG11.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 3, 3, 512)\n",
      " 10 train_loss: 0.632195005 test_loss: 0.531414986 train_accuracy:0.636000003 test_accuracy:0.811320782\n",
      " 20 train_loss: 0.442552579 test_loss: 0.503996849 train_accuracy:0.811999998 test_accuracy:0.735849082\n",
      " 30 train_loss: 0.381399847 test_loss: 0.506302953 train_accuracy:0.851999991 test_accuracy:0.754716992\n",
      " 40 train_loss: 0.351590247 test_loss: 0.496178001 train_accuracy:0.863999991 test_accuracy:0.773584902\n",
      " 50 train_loss: 0.311850747 test_loss: 0.539997518 train_accuracy:0.883999991 test_accuracy:0.773584902\n",
      " 60 train_loss: 0.275454279 test_loss: 0.481428951 train_accuracy:0.899999993 test_accuracy:0.792452812\n",
      " 70 train_loss: 0.235163189 test_loss: 0.504820049 train_accuracy:0.923999991 test_accuracy:0.773584902\n",
      " 80 train_loss: 0.293890982 test_loss: 0.436840475 train_accuracy:0.887999990 test_accuracy:0.811320782\n",
      " 90 train_loss: 0.208074013 test_loss: 0.220585197 train_accuracy:0.911999993 test_accuracy:0.924528301\n",
      "100 train_loss: 0.163698432 test_loss: 0.313347936 train_accuracy:0.939999995 test_accuracy:0.867924511\n",
      "0.8169811342443739\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "cnn_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
