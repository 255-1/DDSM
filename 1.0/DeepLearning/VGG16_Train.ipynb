{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot as plt\n",
    "from Preprocess import label_for_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_path = '/home/user01/Desktop/DDSM/4_benign_Pleo_10_ROI_subpic'#input('良性子图路径')#\n",
    "cancer_path = '/home/user01/Desktop/DDSM/4_cancer_Pleo_10_ROI_subpic'#input('恶性子图路径')#\n",
    "saver_path = '/home/user01/Desktop/DDSM/model/VGG16'#input('模型保存路径')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "train_time = 100\n",
    "batch_size = 10\n",
    "learning_rate = 1e-5\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainsets_and_testsets():\n",
    "    (train_x ,train_y),(test_x,test_y) = label_for_nn(benign_path,cancer_path,scale=0.2,kind='RGB')\n",
    "    train_x = train_x.reshape(train_x.shape[0],size,size,3).astype('float32')/255.0\n",
    "    test_x = test_x.reshape(test_x.shape[0],size,size,3).astype('float32')/255.0\n",
    "    return train_x , test_x ,train_y ,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.027)\n",
    "    return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biases_variable(shape,name):\n",
    "    initial = tf.constant(0.0,shape=shape)\n",
    "    return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_P(x,W,s):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,s,s,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W,s):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,s,s,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_train():\n",
    "    with tf.name_scope('inputs'):\n",
    "        x = tf.placeholder(tf.float32, [None, size, size, 3])\n",
    "        y = tf.placeholder(tf.float32, [None, 2])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "    #conv1#\n",
    "    with tf.name_scope('layer_1'):\n",
    "        with tf.name_scope('weight_1'):\n",
    "            w_conv1 = Weight_variable([3,3,3,64],'w_1')\n",
    "        with tf.name_scope('biases_1'):\n",
    "            b_conv1 = biases_variable([64],'b_1')\n",
    "        with tf.name_scope('conv_1'):\n",
    "            conv1 = tf.nn.relu(conv2d_P(x,w_conv1,1)+b_conv1)\n",
    "    #conv2#\n",
    "    with tf.name_scope('layer_2'):\n",
    "        with tf.name_scope('weight_2'):\n",
    "            w_conv2 = Weight_variable([3,3,64,64],'w_2')\n",
    "        with tf.name_scope('biases_2'):\n",
    "            b_conv2 = biases_variable([64],'b_2')\n",
    "        with tf.name_scope('conv_2'):\n",
    "            conv2 = tf.nn.relu(conv2d_P(conv1,w_conv2,1)+b_conv2)\n",
    "        with tf.name_scope('pool_1'):\n",
    "            pool1 = max_pooling2x2(conv2)\n",
    "    #conv3#\n",
    "    with tf.name_scope('layer_3'):\n",
    "        with tf.name_scope('weight_3'):\n",
    "            w_conv3 = Weight_variable([3,3,64,128],'w_3')\n",
    "        with tf.name_scope('biases_3'):\n",
    "            b_conv3 = biases_variable([128],'b_3')\n",
    "        with tf.name_scope('conv_3'):\n",
    "            conv3 = tf.nn.relu(conv2d_P(pool1,w_conv3,1)+b_conv3)\n",
    "\n",
    "    #conv4#\n",
    "    with tf.name_scope('layer_4'):\n",
    "        with tf.name_scope('weight_4'):\n",
    "            w_conv4 = Weight_variable([3,3,128,128],'w_4')\n",
    "        with tf.name_scope('biases_4'):\n",
    "            b_conv4 = biases_variable([128],'b_4')\n",
    "        with tf.name_scope('conv_4'):\n",
    "            conv4 = tf.nn.relu(conv2d_P(conv3,w_conv4,1)+b_conv4)\n",
    "        with tf.name_scope('pool_2'):\n",
    "            pool2 = max_pooling2x2(conv4)\n",
    "\n",
    "    #conv5#\n",
    "    with tf.name_scope('layer_5'):\n",
    "        with tf.name_scope('weight_5'):\n",
    "            w_conv5 = Weight_variable([3,3,128,256],'w_5')\n",
    "        with tf.name_scope('biases_5'):\n",
    "            b_conv5 = biases_variable([256],'b_5')\n",
    "        with tf.name_scope('conv_5'):\n",
    "            conv5 = tf.nn.relu(conv2d_P(pool2,w_conv5,1)+b_conv5)\n",
    "\n",
    "    #conv6#\n",
    "    with tf.name_scope('layer_6'):\n",
    "        with tf.name_scope('weight_6'):\n",
    "            w_conv6 = Weight_variable([3,3,256,256],'w_6')\n",
    "        with tf.name_scope('biases_6'):\n",
    "            b_conv6 = biases_variable([256],'b_6')\n",
    "        with tf.name_scope('conv_6'):\n",
    "            conv6 = tf.nn.relu(conv2d_P(conv5,w_conv6,1)+b_conv6)\n",
    "\n",
    "    #conv7#\n",
    "    with tf.name_scope('layer_7'):\n",
    "        with tf.name_scope('weight_7'):\n",
    "            w_conv7 = Weight_variable([3,3,256,256],'w_7')\n",
    "        with tf.name_scope('biases_7'):\n",
    "            b_conv7 = biases_variable([256],'b_7')\n",
    "        with tf.name_scope('conv_7'):\n",
    "            conv7 = tf.nn.relu(conv2d_P(conv6,w_conv7,1)+b_conv7)\n",
    "        with tf.name_scope('pool_3'):\n",
    "            pool3 = max_pooling2x2(conv7)\n",
    "\n",
    "    #conv8#\n",
    "    with tf.name_scope('layer_8'):\n",
    "        with tf.name_scope('weight_8'):\n",
    "            w_conv8 = Weight_variable([3,3,256,512],'w_8')\n",
    "        with tf.name_scope('biases_8'):\n",
    "            b_conv8 = biases_variable([512],'b_8')\n",
    "        with tf.name_scope('conv_8'):\n",
    "            conv8 = tf.nn.relu(conv2d_P(pool3,w_conv8,1)+b_conv8)\n",
    "\n",
    "    #conv9#\n",
    "    with tf.name_scope('layer_9'):\n",
    "        with tf.name_scope('weight_9'):\n",
    "            w_conv9 = Weight_variable([3,3,512,512],'w_9')\n",
    "        with tf.name_scope('biases_9'):\n",
    "            b_conv9 = biases_variable([512],'b_9')\n",
    "        with tf.name_scope('conv_9'):\n",
    "            conv9 = tf.nn.relu(conv2d_P(conv8,w_conv9,1)+b_conv9)\n",
    "\n",
    "    #conv10#\n",
    "    with tf.name_scope('layer_10'):\n",
    "        with tf.name_scope('weight_10'):\n",
    "            w_conv10 = Weight_variable([3,3,512,512],'w_10')\n",
    "        with tf.name_scope('biases_10'):\n",
    "            b_conv10 = biases_variable([512],'b_10')\n",
    "        with tf.name_scope('conv_10'):\n",
    "            conv10 = tf.nn.relu(conv2d_P(conv9,w_conv10,1)+b_conv10)\n",
    "        with tf.name_scope('pool_4'):\n",
    "            pool4 = max_pooling2x2(conv10)\n",
    "\n",
    "    #conv11#\n",
    "    with tf.name_scope('layer_11'):\n",
    "        with tf.name_scope('weight_11'):\n",
    "            w_conv11 = Weight_variable([3,3,512,512],'w_11')\n",
    "        with tf.name_scope('biases_11'):\n",
    "            b_conv11 = biases_variable([512],'b_11')\n",
    "        with tf.name_scope('conv_11'):\n",
    "            conv11 = tf.nn.relu(conv2d_P(pool4,w_conv11,1)+b_conv11)\n",
    "\n",
    "    #conv12#\n",
    "    with tf.name_scope('layer_12'):\n",
    "        with tf.name_scope('weight_12'):\n",
    "            w_conv12 = Weight_variable([3,3,512,512],'w_12')\n",
    "        with tf.name_scope('biases_12'):\n",
    "            b_conv12 = biases_variable([512],'b_12')\n",
    "        with tf.name_scope('conv_12'):\n",
    "            conv12 = tf.nn.relu(conv2d_P(conv11,w_conv12,1)+b_conv12)\n",
    "\n",
    "    #conv13#\n",
    "    with tf.name_scope('layer_13'):\n",
    "        with tf.name_scope('weight_13'):\n",
    "            w_conv13 = Weight_variable([3,3,512,512],'w_13')\n",
    "        with tf.name_scope('biases_13'):\n",
    "            b_conv13 = biases_variable([512],'b_13')\n",
    "        with tf.name_scope('conv_13'):\n",
    "            conv13 = tf.nn.relu(conv2d_P(conv12,w_conv13,1)+b_conv13)\n",
    "        with tf.name_scope('pool_5'):\n",
    "            pool5 = max_pooling2x2(conv13)\n",
    "    print(pool5.shape)\n",
    "    #func1#\n",
    "    with tf.name_scope('layer_14'):\n",
    "        with tf.name_scope('weight_14'):\n",
    "            w_conv14 = Weight_variable([3*3*512,4096],'w_14')\n",
    "        with tf.name_scope('biases_14'):\n",
    "            b_conv14 = biases_variable([4096],'b_14')\n",
    "        with tf.name_scope('fc_1'):\n",
    "            pool5_flat = tf.reshape(pool5,[-1,3*3*512])\n",
    "            fc1 = tf.nn.relu(tf.matmul(pool5_flat,w_conv14) + b_conv14)\n",
    "            fc1_drop = tf.nn.dropout(fc1,keep_prob)\n",
    "    #func2#\n",
    "    with tf.name_scope('layer_15'):\n",
    "        with tf.name_scope('weight_15'):\n",
    "            w_conv15 = Weight_variable([4096,4096],'w_15')\n",
    "        with tf.name_scope('biases_15'):\n",
    "            b_conv15 = biases_variable([4096],'b_15')\n",
    "        with tf.name_scope('fc_2'):\n",
    "            fc2 = tf.nn.relu(tf.matmul(fc1_drop,w_conv15) + b_conv15)\n",
    "            fc2_drop = tf.nn.dropout(fc2, keep_prob)\n",
    "    #func3#\n",
    "    with tf.name_scope('layer_16'):\n",
    "        with tf.name_scope('weight_16'):\n",
    "            w_conv16 = Weight_variable([4096,2],'w_16')\n",
    "        with tf.name_scope('biases_16'):\n",
    "            b_conv16 = biases_variable([2],'b_16')\n",
    "        with tf.name_scope('fc_3'):\n",
    "            y_pre = tf.nn.softmax(tf.matmul(fc2_drop,w_conv16) + b_conv16)\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pre), reduction_indices=[1]))\n",
    "    with tf.name_scope('trian'):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "    y_pre_label = tf.argmax(y_pre,1)\n",
    "    y_label = tf.argmax(y,1)\n",
    "    a = tf.add(y_pre_label,1)\n",
    "    b = tf.add(y_label,3)\n",
    "    c = tf.multiply(a,b)\n",
    "    tp = tf.reduce_sum(tf.cast(tf.equal(c,8),tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast(tf.equal(c,6),tf.float32))\n",
    "    tn = tf.reduce_sum(tf.cast(tf.equal(c,3),tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(tf.equal(c,4),tf.float32))\n",
    "    tpr = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    tf.summary.scalar('Sensitivity', tpr)\n",
    "    tf.summary.scalar('Specificity', tnr)\n",
    "    correct_l1 = tf.equal(y_pre_label,y_label)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_l1,tf.float32))\n",
    "    tf.summary.scalar('loss',cross_entropy)\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    init = tf.global_variables_initializer()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    saver = tf.train.Saver({'w_1': w_conv1, 'b_1': b_conv1,\n",
    "                            'w_2': w_conv2, 'b_2': b_conv2,\n",
    "                            'w_3': w_conv3, 'b_3': b_conv3,\n",
    "                            'w_4': w_conv4, 'b_4': b_conv4,\n",
    "                            'w_5': w_conv5, 'b_5': b_conv5,\n",
    "                            'w_6': w_conv6, 'b_6': b_conv6,\n",
    "                            'w_7': w_conv7, 'b_7': b_conv7,\n",
    "                            'w_8': w_conv8, 'b_8': b_conv8,\n",
    "                            'w_9': w_conv9, 'b_9': b_conv9,\n",
    "                            'w_10': w_conv10, 'b_10': b_conv10,\n",
    "                            'w_11': w_conv11, 'b_11': b_conv11,\n",
    "                            'w_12': w_conv12, 'b_12': b_conv12,\n",
    "                            'w_13': w_conv13, 'b_13': b_conv13,\n",
    "                            'w_14': w_conv14, 'b_14': b_conv14,\n",
    "                            'w_15': w_conv15, 'b_15': b_conv15,\n",
    "                            'w_16': w_conv16, 'b_16': b_conv16\n",
    "                            })\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)\n",
    "        writer = tf.summary.FileWriter(saver_path, sess.graph)\n",
    "        sum_test_acc = 0\n",
    "        train_x,test_x,train_y,test_y=get_trainsets_and_testsets()#获取训练集和测试集\n",
    "        num_batch = len(train_x)//batch_size\n",
    "        for n in range(1,train_time+1):\n",
    "            sum_train_acc = 0\n",
    "            av_train_loss = 0\n",
    "            for i in range(num_batch):#训练\n",
    "                batch_x = train_x[i*batch_size : (i+1)*batch_size]\n",
    "                batch_y = train_y[i*batch_size : (i+1)*batch_size]\n",
    "                _,loss,train_acc= sess.run([train_step,cross_entropy,accuracy],feed_dict={x:batch_x,y:batch_y,keep_prob:dropout_rate})\n",
    "                sum_train_acc += train_acc\n",
    "                av_train_loss += loss\n",
    "            av_train_loss /= num_batch\n",
    "            sum_train_acc /= num_batch\n",
    "            test_acc, pre, test_loss = sess.run([accuracy, y_pre, cross_entropy],feed_dict={x: test_x, y: test_y, keep_prob: 1.0})\n",
    "            if n>30:\n",
    "                sum_test_acc += test_acc\n",
    "            print('{0:3d} train_loss: {1:>10.9f} test_loss: {2:>10.9f} train_accuracy:{3:>10.9f} test_accuracy:{4:>10.9f}'.format(n,av_train_loss,test_loss,sum_train_acc,test_acc))\n",
    "            summary = sess.run(merged_summary_op,feed_dict={x:test_x,y:test_y,keep_prob:1.0})\n",
    "            writer.add_summary(summary=summary, global_step=n)\n",
    "        #ROC曲线\n",
    "        y_,y_p= sess.run([y_label,y_pre],feed_dict={x: test_x, y: test_y, keep_prob: 1.0})\n",
    "        temp = []\n",
    "        for i in range(len(y_p)):\n",
    "            temp.append(y_p[i][1])\n",
    "        fpr,tpr,thresholds = roc_curve(y_,temp)\n",
    "        n_auc = auc(fpr,tpr)\n",
    "        plt.plot(fpr,tpr,linewidth=2)\n",
    "        plt.plot([0,1],[0,1],'k--')\n",
    "        plt.axis([0,1,0,1])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        text = 'AUC:'+str(n_auc)[0:5]\n",
    "        plt.text(0.7,0.2,text,fontdict={'size':'12','color':'b'})\n",
    "        saver.save(sess,saver_path+'/VGG16')\n",
    "        print(sum_test_acc/(train_time-30))\n",
    "        plt.savefig(saver_path+'/VGG16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 3, 3, 512)\n",
      "  1 train_loss: 0.693234301 test_loss: 0.694035649 train_accuracy:0.532000005 test_accuracy:0.389830500\n",
      "  2 train_loss: 0.693051112 test_loss: 0.694856942 train_accuracy:0.520000005 test_accuracy:0.389830500\n",
      "  3 train_loss: 0.692856033 test_loss: 0.696093976 train_accuracy:0.516000005 test_accuracy:0.389830500\n",
      "  4 train_loss: 0.692897782 test_loss: 0.699431181 train_accuracy:0.520000007 test_accuracy:0.389830500\n",
      "  5 train_loss: 0.692883353 test_loss: 0.699876845 train_accuracy:0.516000006 test_accuracy:0.389830500\n",
      "  6 train_loss: 0.693014283 test_loss: 0.701144159 train_accuracy:0.516000006 test_accuracy:0.389830500\n",
      "  7 train_loss: 0.691966035 test_loss: 0.701810300 train_accuracy:0.516000006 test_accuracy:0.389830500\n",
      "  8 train_loss: 0.690899670 test_loss: 0.702453136 train_accuracy:0.516000006 test_accuracy:0.389830500\n",
      "  9 train_loss: 0.687516170 test_loss: 0.693818629 train_accuracy:0.516000006 test_accuracy:0.389830500\n",
      " 10 train_loss: 0.663560331 test_loss: 0.664075613 train_accuracy:0.516000006 test_accuracy:0.389830500\n",
      " 11 train_loss: 0.629433094 test_loss: 0.626408875 train_accuracy:0.548000008 test_accuracy:0.389830500\n",
      " 12 train_loss: 0.592822572 test_loss: 0.611026764 train_accuracy:0.660000001 test_accuracy:0.728813589\n",
      " 13 train_loss: 0.598804544 test_loss: 0.620646179 train_accuracy:0.720000001 test_accuracy:0.779661000\n",
      " 14 train_loss: 0.574267057 test_loss: 0.608481705 train_accuracy:0.724000002 test_accuracy:0.694915235\n",
      " 15 train_loss: 0.557943474 test_loss: 0.602675915 train_accuracy:0.755999997 test_accuracy:0.711864412\n",
      " 16 train_loss: 0.542703280 test_loss: 0.594101131 train_accuracy:0.759999994 test_accuracy:0.779661000\n",
      " 17 train_loss: 0.534558446 test_loss: 0.601381004 train_accuracy:0.748000003 test_accuracy:0.762711883\n",
      " 18 train_loss: 0.530091921 test_loss: 0.567074656 train_accuracy:0.759999996 test_accuracy:0.762711883\n",
      " 19 train_loss: 0.500326904 test_loss: 0.513398886 train_accuracy:0.759999996 test_accuracy:0.779661000\n",
      " 20 train_loss: 0.526390514 test_loss: 0.505323172 train_accuracy:0.740000007 test_accuracy:0.779661000\n",
      " 21 train_loss: 0.457588353 test_loss: 0.529424787 train_accuracy:0.803999999 test_accuracy:0.728813589\n",
      " 22 train_loss: 0.508825022 test_loss: 0.489883572 train_accuracy:0.767999994 test_accuracy:0.779661000\n",
      " 23 train_loss: 0.450973450 test_loss: 0.467517972 train_accuracy:0.787999992 test_accuracy:0.779661000\n",
      " 24 train_loss: 0.497953016 test_loss: 0.503594398 train_accuracy:0.755999997 test_accuracy:0.779661000\n",
      " 25 train_loss: 0.441633188 test_loss: 0.468653262 train_accuracy:0.791999998 test_accuracy:0.779661000\n",
      " 26 train_loss: 0.449931795 test_loss: 0.466800183 train_accuracy:0.795999999 test_accuracy:0.796610177\n",
      " 27 train_loss: 0.430777420 test_loss: 0.484926552 train_accuracy:0.811999997 test_accuracy:0.762711883\n",
      " 28 train_loss: 0.454329231 test_loss: 0.450551480 train_accuracy:0.795999997 test_accuracy:0.796610177\n",
      " 29 train_loss: 0.424793832 test_loss: 0.457145780 train_accuracy:0.803999995 test_accuracy:0.762711883\n",
      " 30 train_loss: 0.424874475 test_loss: 0.464401037 train_accuracy:0.819999998 test_accuracy:0.762711883\n",
      " 31 train_loss: 0.439880713 test_loss: 0.438564956 train_accuracy:0.795999998 test_accuracy:0.830508471\n",
      " 32 train_loss: 0.389964888 test_loss: 0.462222219 train_accuracy:0.819999995 test_accuracy:0.779661000\n",
      " 33 train_loss: 0.425328327 test_loss: 0.436146110 train_accuracy:0.811999996 test_accuracy:0.796610177\n",
      " 34 train_loss: 0.399226393 test_loss: 0.431293219 train_accuracy:0.811999993 test_accuracy:0.813559294\n",
      " 35 train_loss: 0.388697982 test_loss: 0.473063320 train_accuracy:0.827999997 test_accuracy:0.796610177\n",
      " 36 train_loss: 0.397529914 test_loss: 0.423978835 train_accuracy:0.823999996 test_accuracy:0.813559294\n",
      " 37 train_loss: 0.376799451 test_loss: 0.418540746 train_accuracy:0.823999994 test_accuracy:0.813559294\n",
      " 38 train_loss: 0.359714473 test_loss: 0.432554662 train_accuracy:0.839999995 test_accuracy:0.813559294\n",
      " 39 train_loss: 0.358740568 test_loss: 0.438063502 train_accuracy:0.851999993 test_accuracy:0.796610177\n",
      " 40 train_loss: 0.345061301 test_loss: 0.432384908 train_accuracy:0.855999994 test_accuracy:0.796610177\n",
      " 41 train_loss: 0.340505955 test_loss: 0.431139350 train_accuracy:0.851999996 test_accuracy:0.813559294\n",
      " 42 train_loss: 0.342172878 test_loss: 0.414771587 train_accuracy:0.855999994 test_accuracy:0.847457647\n",
      " 43 train_loss: 0.331149799 test_loss: 0.404593319 train_accuracy:0.863999994 test_accuracy:0.847457647\n",
      " 44 train_loss: 0.320132186 test_loss: 0.399264008 train_accuracy:0.867999992 test_accuracy:0.847457647\n",
      " 45 train_loss: 0.304886215 test_loss: 0.396515995 train_accuracy:0.871999991 test_accuracy:0.847457647\n",
      " 46 train_loss: 0.288345456 test_loss: 0.386863619 train_accuracy:0.883999991 test_accuracy:0.864406765\n",
      " 47 train_loss: 0.290750911 test_loss: 0.370720416 train_accuracy:0.887999992 test_accuracy:0.881355941\n",
      " 48 train_loss: 0.281802405 test_loss: 0.379272312 train_accuracy:0.899999988 test_accuracy:0.847457647\n",
      " 49 train_loss: 0.293275632 test_loss: 0.368974060 train_accuracy:0.875999990 test_accuracy:0.881355941\n",
      " 50 train_loss: 0.268495234 test_loss: 0.376643866 train_accuracy:0.903999987 test_accuracy:0.864406765\n",
      " 51 train_loss: 0.289959255 test_loss: 0.365165353 train_accuracy:0.879999993 test_accuracy:0.864406765\n",
      " 52 train_loss: 0.290834252 test_loss: 0.380071521 train_accuracy:0.891999993 test_accuracy:0.881355941\n",
      " 53 train_loss: 0.246255492 test_loss: 0.346570969 train_accuracy:0.923999991 test_accuracy:0.864406765\n",
      " 54 train_loss: 0.283192958 test_loss: 0.386957794 train_accuracy:0.891999996 test_accuracy:0.847457647\n",
      " 55 train_loss: 0.321359666 test_loss: 0.478075236 train_accuracy:0.868000000 test_accuracy:0.779661000\n",
      " 56 train_loss: 0.319114645 test_loss: 0.333778411 train_accuracy:0.867999997 test_accuracy:0.881355941\n",
      " 57 train_loss: 0.314917414 test_loss: 0.355422229 train_accuracy:0.851999998 test_accuracy:0.881355941\n",
      " 58 train_loss: 0.314716923 test_loss: 0.467136383 train_accuracy:0.859999993 test_accuracy:0.728813589\n",
      " 59 train_loss: 0.312871896 test_loss: 0.519734919 train_accuracy:0.855999987 test_accuracy:0.728813589\n",
      " 60 train_loss: 0.276942477 test_loss: 0.510046303 train_accuracy:0.871999993 test_accuracy:0.728813589\n",
      " 61 train_loss: 0.283436844 test_loss: 0.573825955 train_accuracy:0.867999995 test_accuracy:0.661016941\n",
      " 62 train_loss: 0.284866535 test_loss: 0.406329095 train_accuracy:0.855999992 test_accuracy:0.830508471\n",
      " 63 train_loss: 0.205654187 test_loss: 0.368613333 train_accuracy:0.923999994 test_accuracy:0.813559294\n",
      " 64 train_loss: 0.227711646 test_loss: 0.488255024 train_accuracy:0.907999992 test_accuracy:0.796610177\n",
      " 65 train_loss: 0.275329003 test_loss: 0.691211164 train_accuracy:0.855999992 test_accuracy:0.627118647\n",
      " 66 train_loss: 0.303845108 test_loss: 0.320305616 train_accuracy:0.867999990 test_accuracy:0.898305058\n",
      " 67 train_loss: 0.170969312 test_loss: 0.321394950 train_accuracy:0.939999993 test_accuracy:0.864406765\n",
      " 68 train_loss: 0.173340720 test_loss: 0.309808105 train_accuracy:0.935999997 test_accuracy:0.881355941\n",
      " 69 train_loss: 0.176564638 test_loss: 0.275216818 train_accuracy:0.935999992 test_accuracy:0.915254235\n",
      " 70 train_loss: 0.161597710 test_loss: 0.282126665 train_accuracy:0.943999991 test_accuracy:0.915254235\n",
      " 71 train_loss: 0.160290433 test_loss: 0.284362257 train_accuracy:0.947999992 test_accuracy:0.932203412\n",
      " 72 train_loss: 0.147867285 test_loss: 0.395384133 train_accuracy:0.951999993 test_accuracy:0.881355941\n",
      " 73 train_loss: 0.130403984 test_loss: 0.342363864 train_accuracy:0.951999993 test_accuracy:0.881355941\n",
      " 74 train_loss: 0.102606831 test_loss: 0.267796814 train_accuracy:0.971999996 test_accuracy:0.915254235\n",
      " 75 train_loss: 0.107218318 test_loss: 0.279014379 train_accuracy:0.963999994 test_accuracy:0.898305058\n",
      " 76 train_loss: 0.090210591 test_loss: 0.293719828 train_accuracy:0.975999994 test_accuracy:0.881355941\n",
      " 77 train_loss: 0.222087476 test_loss: 0.436135083 train_accuracy:0.899999993 test_accuracy:0.881355941\n",
      " 78 train_loss: 0.111272426 test_loss: 0.318614542 train_accuracy:0.959999995 test_accuracy:0.847457647\n",
      " 79 train_loss: 0.089936668 test_loss: 0.326157659 train_accuracy:0.971999993 test_accuracy:0.898305058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80 train_loss: 0.108427649 test_loss: 0.392040581 train_accuracy:0.963999994 test_accuracy:0.830508471\n",
      " 81 train_loss: 0.109922688 test_loss: 0.423144400 train_accuracy:0.955999990 test_accuracy:0.830508471\n",
      " 82 train_loss: 0.180372275 test_loss: 0.576824188 train_accuracy:0.907999992 test_accuracy:0.847457647\n",
      " 83 train_loss: 0.080521097 test_loss: 0.288179278 train_accuracy:0.971999993 test_accuracy:0.898305058\n",
      " 84 train_loss: 0.109376524 test_loss: 0.513333976 train_accuracy:0.963999994 test_accuracy:0.779661000\n",
      " 85 train_loss: 0.131223934 test_loss: 0.541412890 train_accuracy:0.955999994 test_accuracy:0.881355941\n",
      " 86 train_loss: 0.061306613 test_loss: 0.401023120 train_accuracy:0.979999995 test_accuracy:0.898305058\n",
      " 87 train_loss: 0.091728810 test_loss: 0.507685423 train_accuracy:0.967999995 test_accuracy:0.915254235\n",
      " 88 train_loss: 0.218583330 test_loss: 0.667127788 train_accuracy:0.911999993 test_accuracy:0.796610177\n",
      " 89 train_loss: 0.103592518 test_loss: 0.304924726 train_accuracy:0.967999992 test_accuracy:0.898305058\n",
      " 90 train_loss: 0.083433865 test_loss: 0.344569445 train_accuracy:0.967999995 test_accuracy:0.898305058\n",
      " 91 train_loss: 0.047284288 test_loss: 0.377172858 train_accuracy:0.987999997 test_accuracy:0.898305058\n",
      " 92 train_loss: 0.044027703 test_loss: 0.551318645 train_accuracy:0.991999998 test_accuracy:0.881355941\n",
      " 93 train_loss: 0.039114415 test_loss: 0.530743837 train_accuracy:0.991999998 test_accuracy:0.881355941\n",
      " 94 train_loss: 0.035471585 test_loss: 0.525375187 train_accuracy:0.995999999 test_accuracy:0.881355941\n",
      " 95 train_loss: 0.042745855 test_loss: 0.541885734 train_accuracy:0.987999997 test_accuracy:0.881355941\n",
      " 96 train_loss: 0.041595772 test_loss: 0.801233470 train_accuracy:0.979999995 test_accuracy:0.881355941\n",
      " 97 train_loss: 0.031967008 test_loss: 0.457258135 train_accuracy:0.995999999 test_accuracy:0.881355941\n",
      " 98 train_loss: 0.040160936 test_loss: 0.668504775 train_accuracy:0.991999998 test_accuracy:0.881355941\n",
      " 99 train_loss: 0.035012869 test_loss: 0.719691455 train_accuracy:0.995999999 test_accuracy:0.881355941\n",
      "100 train_loss: 0.080217563 test_loss: 0.447393268 train_accuracy:0.971999996 test_accuracy:0.881355941\n",
      "0.8472154957907541\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "cnn_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
