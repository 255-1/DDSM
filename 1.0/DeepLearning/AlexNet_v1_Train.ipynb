{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot as plt\n",
    "from Preprocess import label_for_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_path = '/home/user01/Desktop/DDSM/4_benign_Pleo_10_ROI_subpic'#input('良性子图路径')#\n",
    "cancer_path = '/home/user01/Desktop/DDSM/4_cancer_Pleo_10_ROI_subpic'#input('恶性子图路径')#\n",
    "saver_path = '/home/user01/Desktop/DDSM/model/AlexNet_v1'#input('模型保存路径')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "train_time = 100\n",
    "batch_size = 25\n",
    "learning_rate = 6e-5\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainsets_and_testsets():\n",
    "    (train_x ,train_y),(test_x,test_y) = label_for_nn(benign_path,cancer_path,scale=0.2,kind='RGB')\n",
    "    train_x = train_x.reshape(train_x.shape[0],size,size,3).astype('float32')/255.0\n",
    "    test_x = test_x.reshape(test_x.shape[0],size,size,3).astype('float32')/255.0\n",
    "    return train_x , test_x ,train_y ,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.05)\n",
    "    return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biases_variable(shape,name):\n",
    "    initial = tf.constant(0.0,shape=shape)\n",
    "    return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_P(x,W,s):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,s,s,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W,s):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,s,s,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_train():\n",
    "    with tf.name_scope('inputs'):\n",
    "        x = tf.placeholder(tf.float32, [None, size, size, 3])\n",
    "        y = tf.placeholder(tf.float32, [None, 2])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "    # conv1#\n",
    "    with tf.name_scope('layer_1'):\n",
    "        with tf.name_scope('weight_1'):\n",
    "            w_conv1 = Weight_variable([11, 11, 3, 64],'w_1') # 128\n",
    "        with tf.name_scope('biases_1'):\n",
    "            b_conv1 = biases_variable([64],'b_1')\n",
    "        with tf.name_scope('conv_1'):\n",
    "            h_conv1 = tf.nn.relu(conv2d_P(x, w_conv1, 4) + b_conv1)\n",
    "        with tf.name_scope('pool_1'):\n",
    "            h_pool1 = max_pooling2x2(h_conv1)\n",
    "    #conv2\n",
    "    with tf.name_scope('layer_2'):\n",
    "        with tf.name_scope('weight_2'):\n",
    "            w_conv2 = Weight_variable([5, 5, 64, 192],'w_2')  # 43-5+1=39*39*32\n",
    "        with tf.name_scope('biases_2'):\n",
    "            b_conv2 = biases_variable([192],'b_2')\n",
    "        with tf.name_scope('conv_2'):\n",
    "            h_conv2 = tf.nn.relu(conv2d_P(h_pool1, w_conv2, 1) + b_conv2)\n",
    "        with tf.name_scope('pool_2'):\n",
    "            h_pool2 = max_pooling2x2(h_conv2)\n",
    "    #conv3\n",
    "    with tf.name_scope('layer_3'):\n",
    "        with tf.name_scope('weight_3'):\n",
    "            w_conv3 = Weight_variable([3, 3, 192, 384],'w_3')  # 13-5+1 = 9*9*64\n",
    "        with tf.name_scope('biases_3'):\n",
    "            b_conv3 = biases_variable([384],'b_3')\n",
    "        with tf.name_scope('conv_3'):\n",
    "            h_conv3 = tf.nn.relu(conv2d_P(h_pool2,w_conv3, 1) +b_conv3)\n",
    "    #conv4\n",
    "    with tf.name_scope('layer_4'):\n",
    "        with tf.name_scope('weight_4'):\n",
    "            w_conv4 = Weight_variable([3, 3, 384, 256],'w_4')\n",
    "        with tf.name_scope('biases_4'):\n",
    "            b_conv4 = biases_variable([256],'b_4')\n",
    "        with tf.name_scope('conv_4'):\n",
    "            h_conv4 = tf.nn.relu(conv2d_P(h_conv3, w_conv4, 1) + b_conv4)\n",
    "    #conv5\n",
    "    with tf.name_scope('layer_5'):\n",
    "        with tf.name_scope('weight_5'):\n",
    "            w_conv5 = Weight_variable([3, 3, 256, 256],'w_5')\n",
    "        with tf.name_scope('biases_5'):\n",
    "            b_conv5 = biases_variable([256],'b_5')\n",
    "        with tf.name_scope('conv_5'):\n",
    "            h_conv5 = tf.nn.relu(conv2d_P(h_conv4,w_conv5, 1) + b_conv5)\n",
    "        with tf.name_scope('pool_3'):\n",
    "            h_pool3 = max_pooling2x2(h_conv5)\n",
    "    # func1#\n",
    "    with tf.name_scope('layer_6'):\n",
    "        with tf.name_scope('weight_6'):\n",
    "            w_conv6 = Weight_variable([3 * 3 * 256, 4096],'w_6')\n",
    "        with tf.name_scope('biases_6'):\n",
    "            b_conv6 = biases_variable([4096],'b_6')\n",
    "        with tf.name_scope('fc_1'):\n",
    "            pool5_flat = tf.reshape(h_pool3, [-1,3 * 3 * 256])\n",
    "            fc1 = tf.nn.relu(tf.matmul(pool5_flat, w_conv6) + b_conv6)\n",
    "            fc1_drop = tf.nn.dropout(fc1, keep_prob)\n",
    "    # func2#\n",
    "    with tf.name_scope('layer_7'):\n",
    "        with tf.name_scope('weight_7'):\n",
    "            w_conv7 = Weight_variable([4096, 4096],'w_7')\n",
    "        with tf.name_scope('biases_7'):\n",
    "            b_conv7 = biases_variable([4096],'b_7')\n",
    "        with tf.name_scope('fc_2'):\n",
    "            fc2 = tf.nn.relu(tf.matmul(fc1_drop, w_conv7) + b_conv7)\n",
    "            fc2_drop = tf.nn.dropout(fc2, keep_prob)\n",
    "    # func3#\n",
    "    with tf.name_scope('layer_8'):\n",
    "        with tf.name_scope('weight_8'):\n",
    "            w_conv8 = Weight_variable([4096, 2],'w_8')\n",
    "        with tf.name_scope('biases_8'):\n",
    "            b_conv8 = biases_variable([2],'b_8')\n",
    "        with tf.name_scope('fc_3'):\n",
    "            y_pre = tf.nn.softmax(tf.matmul(fc2_drop, w_conv8) + b_conv8)\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pre), reduction_indices=[1]))\n",
    "    with tf.name_scope('trian'):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "    y_pre_label = tf.argmax(y_pre,1)\n",
    "    y_label = tf.argmax(y,1)\n",
    "    a = tf.add(y_pre_label,1)\n",
    "    b = tf.add(y_label,3)\n",
    "    c = tf.multiply(a,b)\n",
    "    tp = tf.reduce_sum(tf.cast(tf.equal(c,8),tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast(tf.equal(c,6),tf.float32))\n",
    "    tn = tf.reduce_sum(tf.cast(tf.equal(c,3),tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(tf.equal(c,4),tf.float32))\n",
    "    tpr = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    tf.summary.scalar('Sensitivity', tpr)\n",
    "    tf.summary.scalar('Specificity', tnr)\n",
    "    correct_l1 = tf.equal(y_pre_label,y_label)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_l1,tf.float32))\n",
    "    tf.summary.scalar('loss',cross_entropy)\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    init = tf.global_variables_initializer()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    saver = tf.train.Saver({'w_1': w_conv1, 'b_1': b_conv1,\n",
    "                            'w_2': w_conv2, 'b_2': b_conv2,\n",
    "                            'w_3': w_conv3, 'b_3': b_conv3,\n",
    "                            'w_4': w_conv4, 'b_4': b_conv4,\n",
    "                            'w_5': w_conv5, 'b_5': b_conv5,\n",
    "                            'w_6': w_conv6, 'b_6': b_conv6,\n",
    "                            'w_7': w_conv7, 'b_7': b_conv7,\n",
    "                            'w_8': w_conv8, 'b_8': b_conv8\n",
    "                            })\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)\n",
    "        writer = tf.summary.FileWriter(saver_path, sess.graph)\n",
    "        sum_test_acc = 0\n",
    "        train_x,test_x,train_y,test_y=get_trainsets_and_testsets()#获取训练集和测试集\n",
    "        num_batch = len(train_x)//batch_size\n",
    "        for n in range(1,train_time+1):\n",
    "            sum_train_acc = 0\n",
    "            av_train_loss = 0\n",
    "            for i in range(num_batch):#训练\n",
    "                batch_x = train_x[i*batch_size : (i+1)*batch_size]\n",
    "                batch_y = train_y[i*batch_size : (i+1)*batch_size]\n",
    "                _,loss,train_acc= sess.run([train_step,cross_entropy,accuracy],feed_dict={x:batch_x,y:batch_y,keep_prob:dropout_rate})\n",
    "                sum_train_acc += train_acc\n",
    "                av_train_loss += loss\n",
    "            av_train_loss /= num_batch\n",
    "            sum_train_acc /= num_batch\n",
    "            test_acc, pre, test_loss = sess.run([accuracy, y_pre, cross_entropy],feed_dict={x: test_x, y: test_y, keep_prob: 1.0})\n",
    "            if n>30:\n",
    "                sum_test_acc += test_acc\n",
    "            #验证\n",
    "            print('{0:3d} train_loss: {1:>10.9f} test_loss: {2:>10.9f} train_accuracy:{3:>10.9f} test_accuracy:{4:>10.9f}'.format(n,av_train_loss,test_loss,sum_train_acc,test_acc))\n",
    "            summary = sess.run(merged_summary_op,feed_dict={x:test_x,y:test_y,keep_prob:1.0})\n",
    "            writer.add_summary(summary=summary, global_step=n)\n",
    "        #ROC曲线\n",
    "        y_,y_p= sess.run([y_label,y_pre],feed_dict={x: test_x, y: test_y, keep_prob: 1.0})\n",
    "        temp = []\n",
    "        for i in range(len(y_p)):\n",
    "            temp.append(y_p[i][1])\n",
    "        fpr,tpr,thresholds = roc_curve(y_,temp)\n",
    "        n_auc = auc(fpr,tpr)\n",
    "        plt.plot(fpr,tpr,linewidth=2)\n",
    "        plt.plot([0,1],[0,1],'k--')\n",
    "        plt.axis([0,1,0,1])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        text = 'AUC:'+str(n_auc)[0:5]\n",
    "        plt.text(0.7,0.2,text,fontdict={'size':'12','color':'b'})\n",
    "        saver.save(sess,saver_path+'/AlexNet')\n",
    "        print(sum_test_acc/(train_time-30))\n",
    "        plt.savefig(saver_path+'/AlexNet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 train_loss: 0.732424182 test_loss: 0.687576652 train_accuracy:0.488000003 test_accuracy:0.473684222\n",
      "  2 train_loss: 0.676422912 test_loss: 0.650260568 train_accuracy:0.591999990 test_accuracy:0.649122834\n",
      "  3 train_loss: 0.633758879 test_loss: 0.628666699 train_accuracy:0.612000006 test_accuracy:0.684210539\n",
      "  4 train_loss: 0.608446717 test_loss: 0.604785144 train_accuracy:0.676000005 test_accuracy:0.736842096\n",
      "  5 train_loss: 0.572279865 test_loss: 0.576753914 train_accuracy:0.684000009 test_accuracy:0.736842096\n",
      "  6 train_loss: 0.536500818 test_loss: 0.546446323 train_accuracy:0.700000006 test_accuracy:0.736842096\n",
      "  7 train_loss: 0.484986770 test_loss: 0.522342384 train_accuracy:0.772000003 test_accuracy:0.789473712\n",
      "  8 train_loss: 0.460751098 test_loss: 0.509600878 train_accuracy:0.751999998 test_accuracy:0.789473712\n",
      "  9 train_loss: 0.456349885 test_loss: 0.504718125 train_accuracy:0.764000005 test_accuracy:0.807017565\n",
      " 10 train_loss: 0.427312273 test_loss: 0.496698976 train_accuracy:0.788000000 test_accuracy:0.789473712\n",
      " 11 train_loss: 0.428107306 test_loss: 0.518424809 train_accuracy:0.775999999 test_accuracy:0.719298244\n",
      " 12 train_loss: 0.391764733 test_loss: 0.528205097 train_accuracy:0.827999997 test_accuracy:0.719298244\n",
      " 13 train_loss: 0.338849166 test_loss: 0.459948093 train_accuracy:0.867999995 test_accuracy:0.719298244\n",
      " 14 train_loss: 0.286779992 test_loss: 0.411301017 train_accuracy:0.887999988 test_accuracy:0.789473712\n",
      " 15 train_loss: 0.239988344 test_loss: 0.408556104 train_accuracy:0.907999998 test_accuracy:0.842105269\n",
      " 16 train_loss: 0.207765625 test_loss: 0.378772527 train_accuracy:0.935999995 test_accuracy:0.824561417\n",
      " 17 train_loss: 0.179264908 test_loss: 0.364367068 train_accuracy:0.951999998 test_accuracy:0.859649122\n",
      " 18 train_loss: 0.137650591 test_loss: 0.363155931 train_accuracy:0.963999999 test_accuracy:0.859649122\n",
      " 19 train_loss: 0.104874866 test_loss: 0.304821074 train_accuracy:0.991999996 test_accuracy:0.894736826\n",
      " 20 train_loss: 0.102739417 test_loss: 0.290722519 train_accuracy:0.959999996 test_accuracy:0.894736826\n",
      " 21 train_loss: 0.075402809 test_loss: 0.283811927 train_accuracy:0.991999996 test_accuracy:0.929824591\n",
      " 22 train_loss: 0.059219352 test_loss: 0.403193504 train_accuracy:0.991999996 test_accuracy:0.824561417\n",
      " 23 train_loss: 0.041065577 test_loss: 0.374785602 train_accuracy:0.995999998 test_accuracy:0.894736826\n",
      " 24 train_loss: 0.028266252 test_loss: 0.292458504 train_accuracy:1.000000000 test_accuracy:0.894736826\n",
      " 25 train_loss: 0.019894858 test_loss: 0.286935627 train_accuracy:1.000000000 test_accuracy:0.859649122\n",
      " 26 train_loss: 0.021195083 test_loss: 0.281458497 train_accuracy:1.000000000 test_accuracy:0.894736826\n",
      " 27 train_loss: 0.013653862 test_loss: 0.346097022 train_accuracy:1.000000000 test_accuracy:0.859649122\n",
      " 28 train_loss: 0.014239287 test_loss: 0.312729865 train_accuracy:1.000000000 test_accuracy:0.877192974\n",
      " 29 train_loss: 0.015218149 test_loss: 0.461149782 train_accuracy:1.000000000 test_accuracy:0.842105269\n",
      " 30 train_loss: 0.016329202 test_loss: 0.248593286 train_accuracy:0.991999996 test_accuracy:0.894736826\n",
      " 31 train_loss: 0.018363722 test_loss: 0.309732139 train_accuracy:0.995999998 test_accuracy:0.894736826\n",
      " 32 train_loss: 0.014665952 test_loss: 0.264983207 train_accuracy:1.000000000 test_accuracy:0.859649122\n",
      " 33 train_loss: 0.013474115 test_loss: 0.389774591 train_accuracy:1.000000000 test_accuracy:0.842105269\n",
      " 34 train_loss: 0.009517395 test_loss: 0.592004716 train_accuracy:0.995999998 test_accuracy:0.807017565\n",
      " 35 train_loss: 0.061028336 test_loss: 0.297976881 train_accuracy:0.971999991 test_accuracy:0.912280679\n",
      " 36 train_loss: 0.407904869 test_loss: 1.229969263 train_accuracy:0.891999999 test_accuracy:0.701754391\n",
      " 37 train_loss: 0.204933755 test_loss: 0.237589851 train_accuracy:0.919999993 test_accuracy:0.912280679\n",
      " 38 train_loss: 0.067640591 test_loss: 0.339830339 train_accuracy:0.995999998 test_accuracy:0.842105269\n",
      " 39 train_loss: 0.052979213 test_loss: 0.198403820 train_accuracy:0.991999996 test_accuracy:0.947368443\n",
      " 40 train_loss: 0.020914439 test_loss: 0.258830070 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 41 train_loss: 0.022699105 test_loss: 0.184797168 train_accuracy:0.995999998 test_accuracy:0.947368443\n",
      " 42 train_loss: 0.013266228 test_loss: 0.225343019 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 43 train_loss: 0.009654279 test_loss: 0.236982316 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 44 train_loss: 0.008410490 test_loss: 0.229716361 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 45 train_loss: 0.006191022 test_loss: 0.202355534 train_accuracy:1.000000000 test_accuracy:0.947368443\n",
      " 46 train_loss: 0.004395255 test_loss: 0.213751480 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 47 train_loss: 0.005179434 test_loss: 0.195519015 train_accuracy:1.000000000 test_accuracy:0.947368443\n",
      " 48 train_loss: 0.003407277 test_loss: 0.240099505 train_accuracy:1.000000000 test_accuracy:0.894736826\n",
      " 49 train_loss: 0.002864651 test_loss: 0.206036821 train_accuracy:1.000000000 test_accuracy:0.947368443\n",
      " 50 train_loss: 0.003913829 test_loss: 0.221862659 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 51 train_loss: 0.002795044 test_loss: 0.207905591 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 52 train_loss: 0.002224539 test_loss: 0.219912037 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 53 train_loss: 0.001848179 test_loss: 0.227603972 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 54 train_loss: 0.001586473 test_loss: 0.213573202 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 55 train_loss: 0.001694324 test_loss: 0.213896841 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 56 train_loss: 0.002972855 test_loss: 0.175126225 train_accuracy:1.000000000 test_accuracy:0.982456148\n",
      " 57 train_loss: 0.001571602 test_loss: 0.262733489 train_accuracy:1.000000000 test_accuracy:0.894736826\n",
      " 58 train_loss: 0.001756789 test_loss: 0.249763086 train_accuracy:1.000000000 test_accuracy:0.894736826\n",
      " 59 train_loss: 0.001565165 test_loss: 0.209260672 train_accuracy:1.000000000 test_accuracy:0.947368443\n",
      " 60 train_loss: 0.001097149 test_loss: 0.247929379 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 61 train_loss: 0.001016240 test_loss: 0.257811785 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 62 train_loss: 0.000868627 test_loss: 0.248147741 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 63 train_loss: 0.001194434 test_loss: 0.255780578 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 64 train_loss: 0.001251584 test_loss: 0.285956740 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 65 train_loss: 0.001101038 test_loss: 0.202800229 train_accuracy:1.000000000 test_accuracy:0.947368443\n",
      " 66 train_loss: 0.001019043 test_loss: 0.227391869 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 67 train_loss: 0.001425285 test_loss: 0.247627005 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 68 train_loss: 0.000854388 test_loss: 0.253728002 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 69 train_loss: 0.000717487 test_loss: 0.253318161 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 70 train_loss: 0.000756975 test_loss: 0.247202784 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 71 train_loss: 0.000813563 test_loss: 0.233812839 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 72 train_loss: 0.000984645 test_loss: 0.225512683 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 73 train_loss: 0.000623786 test_loss: 0.266226023 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 74 train_loss: 0.000528158 test_loss: 0.268454969 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 75 train_loss: 0.000473858 test_loss: 0.239156976 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 76 train_loss: 0.000425384 test_loss: 0.237947494 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 77 train_loss: 0.000553171 test_loss: 0.242239550 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 78 train_loss: 0.000410989 test_loss: 0.250919968 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 79 train_loss: 0.000416657 test_loss: 0.240166426 train_accuracy:1.000000000 test_accuracy:0.929824591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80 train_loss: 0.000324927 test_loss: 0.243590251 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 81 train_loss: 0.000470511 test_loss: 0.235026315 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 82 train_loss: 0.000653145 test_loss: 0.227148712 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 83 train_loss: 0.000342440 test_loss: 0.266106933 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 84 train_loss: 0.000413061 test_loss: 0.280105799 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 85 train_loss: 0.000469214 test_loss: 0.233756334 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 86 train_loss: 0.000338614 test_loss: 0.245929658 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 87 train_loss: 0.000378845 test_loss: 0.284429491 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 88 train_loss: 0.000393488 test_loss: 0.256743729 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 89 train_loss: 0.000332163 test_loss: 0.261540741 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 90 train_loss: 0.000377909 test_loss: 0.285742700 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 91 train_loss: 0.000362105 test_loss: 0.269412458 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 92 train_loss: 0.000264904 test_loss: 0.277644783 train_accuracy:1.000000000 test_accuracy:0.912280679\n",
      " 93 train_loss: 0.000289998 test_loss: 0.259499192 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 94 train_loss: 0.000209416 test_loss: 0.253521413 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 95 train_loss: 0.000237152 test_loss: 0.256103665 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 96 train_loss: 0.000199044 test_loss: 0.257518440 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 97 train_loss: 0.000201192 test_loss: 0.262575448 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 98 train_loss: 0.000185882 test_loss: 0.265759975 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      " 99 train_loss: 0.000193286 test_loss: 0.260792762 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      "100 train_loss: 0.000167510 test_loss: 0.263778150 train_accuracy:1.000000000 test_accuracy:0.929824591\n",
      "0.9157894798687526\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/home/user01/anaconda3/envs/RR/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "cnn_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
